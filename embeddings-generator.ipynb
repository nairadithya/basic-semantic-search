{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search Engine Built With Embeddings\n",
    "\n",
    "This is the first demonstration of an embeddings based search engine.\n",
    "\n",
    "The benefits of this search engine is the ability to search for _meaning_ rather than just keyword matching. LLMs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL WARNING\n",
    "Do not run this notebook without `uv` and the venv required.\n",
    "\n",
    "## Opening these notebooks for the first time.\n",
    "To install all the dependencies required to execute this notebook, type `uv sync` in the root of the git repo.\n",
    "\n",
    "To run this notebook and ensure that `uv` is taking care of your packages, run this command\n",
    "\n",
    "### For Jupyter Lab\n",
    "```sh\n",
    "uv run --with jupyter jupyter lab\n",
    "```\n",
    "\n",
    "## VS Code\n",
    "Install the required Jupyter/Python extensions\n",
    "\n",
    "When asked for a kernel, select `.venv/bin/python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we're loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y6PMewKczUPD",
    "outputId": "a61c76de-8be8-4412-f1f9-ebd4a36efc8b"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dictionary_dataset = load_dataset(\"MAKILINGDING/english_dictionary\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_dataset.set_format(\"pandas\")\n",
    "df = dictionary_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>the first letter of the english and of many ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a 1</td>\n",
       "      <td>a registry mark given by underwriters (as at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a b c</td>\n",
       "      <td>the first three letters of the alphabet, used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>in church or chapel style; -- said of composit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a fortiori</td>\n",
       "      <td>with stronger reason.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                         definition\n",
       "0           a  the first letter of the english and of many ot...\n",
       "1         a 1  a registry mark given by underwriters (as at l...\n",
       "2       a b c  the first three letters of the alphabet, used ...\n",
       "3  a cappella  in church or chapel style; -- said of composit...\n",
       "4  a fortiori                              with stronger reason."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining word and definition into a column called `combined` to feed to the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AdsQeoiUzUPG"
   },
   "outputs": [],
   "source": [
    "cols = ['word', 'definition']\n",
    "df['combined'] = df[cols].apply(lambda row: '\\n'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into a Dataset object\n",
    "This allows us to use a hugging face model and its library for transformers directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['word', 'definition', 'combined'],\n",
       "    num_rows: 124088\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dictionary_dataset = Dataset.from_pandas(df)\n",
    "dictionary_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tread very carefully from here.\n",
    "This involves training the model, we have the embeddings dataset already so there is no need to run this code again.\n",
    "I am only keeping the code here for understanding purposes.\n",
    "\n",
    "Run this code if you know what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pytorch\n",
    "Given that my laptop only had a CPU, `torch.device()` was passed the `\"cpu\"` parameter. If you have an NVIDIA GPU, replace `\"cpu\"` with `\"cuda\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dUwml5tzzUPH",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About The Transformer Being Used\n",
    "I chose `multi-qa-mpnet-base-dot-v1` since it's a decently sized transformer, which is *built* for semantic search.\n",
    "\n",
    "It has been trained on 215M (question, answer) pairs from diverse sources. So it's good at creating sentence embeddings, since we're working with definitions... this is exactly what we need.\n",
    "\n",
    "This model is based off the [mpnet-base](https://huggingface.co/microsoft/mpnet-base) model from Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AVCFIpp2zUPI"
   },
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C_GziK6KzUPI"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xbINRBwczUPI",
    "outputId": "269a8097-8c17-45d8-a44f-61e0332c1760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = get_embeddings(dictionary_dataset[\"combined\"][0])\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just to show the embeddings size, our transformer outputs vectors of a size $(1 \\times 768)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ED-V7jLbzUPI"
   },
   "outputs": [],
   "source": [
    "embeddings_dataset = dictionary_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"combined\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was run and generated an embeddings dataset.\n",
    "\n",
    "The following code saved it to a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset.to_csv(dictionary_embeddings.csv, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the actual search part of the model, check the `semantic-search-with-dataset.ipynb` notebook in this repo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Semantic search with FAISS (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
